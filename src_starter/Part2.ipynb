{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and train SVD for embedding extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My prediction: 3.0605793703642816, SVD's prediction: 3.0605793703642816, difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, NormalPredictor, Reader, SVD, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "# Load the dataset in the same way as the main problem \n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "        load_train_valid_test_datasets()\n",
    "\n",
    "\n",
    "def tuple_to_surprise_dataset(tupl):\n",
    "    \"\"\"\n",
    "    This function convert a subset in the tuple form to a `surprise` dataset. \n",
    "    \"\"\"\n",
    "    ratings_dict = {\n",
    "        \"userID\": tupl[0],\n",
    "        \"itemID\": tupl[1],\n",
    "        \"rating\": tupl[2],\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "    # A reader is still needed but only the rating_scale param is requiered.\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    dataset = Dataset.load_from_df(df[[\"userID\", \"itemID\", \"rating\"]], reader)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "## Below we train an SVD model and get its vectors \n",
    "\n",
    "# train an SVD model using the training set\n",
    "trainset = tuple_to_surprise_dataset(train_tuple).build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "\n",
    "# Use an example to show to to slice out user and item vectors learned by the SVD \n",
    "uid = valid_tuple[0][0]\n",
    "iid = valid_tuple[1][0]\n",
    "rui = valid_tuple[2][0]\n",
    "\n",
    "# Get model parameters\n",
    "# NOTE: the SVD model has its own index system because the storage using raw user and item ids\n",
    "# is not efficient. We need to convert raw ids to internal ids. Please read the few lines below\n",
    "# carefully \n",
    "\n",
    "mu = algo.trainset.global_mean # SVD does not even fit mu -- it directly use the rating mean \n",
    "bu = algo.bu[trainset.to_inner_uid(uid)]\n",
    "bi = algo.bi[trainset.to_inner_iid(iid)] \n",
    "pu = algo.pu[trainset.to_inner_uid(uid)] \n",
    "qi = algo.qi[trainset.to_inner_iid(iid)]\n",
    "\n",
    "# Sanity check: we compute our own prediction and compare it against the model's prediction \n",
    "# our prediction\n",
    "my_est = mu + bu + bi + np.dot(pu, qi) \n",
    "\n",
    "# the model's prediction\n",
    "# NOTE: the training of the SVD model is random, so the prediction can be different with \n",
    "# different runs -- this is normal.   \n",
    "svd_pred = algo.predict(uid, iid, r_ui=rui)\n",
    "\n",
    "# The two predictions should be the same\n",
    "print(\"My prediction: \" + str(my_est) + \", SVD's prediction: \" + str(svd_pred.est) + \", difference: \" + str(np.abs(my_est - svd_pred.est)))\n",
    "\n",
    "assert(np.abs(my_est - svd_pred.est) < 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in user and movies info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_df = pd.read_csv('../data_movie_lens_100k/user_info.csv')\n",
    "movie_info_df = pd.read_csv('../data_movie_lens_100k/movie_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Clean Up and Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Movies Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming you have loaded the movie information into a DataFrame called 'movies_df'\n",
    "movie_titles = movie_info_df['title'].tolist()\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the movie titles\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movie_titles)\n",
    "\n",
    "# Convert the TF-IDF matrix to a dense numpy array\n",
    "tfidf_features = tfidf_matrix.toarray()\n",
    "\n",
    "# Combine the TF-IDF features with other movie features\n",
    "movie_features = np.hstack((tfidf_features, movie_info_df[['release_year']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_features = movie_info_df[['release_year']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  24   1]\n",
      " [  1  53   0]\n",
      " [  2  23   1]\n",
      " ...\n",
      " [940  20   1]\n",
      " [941  48   0]\n",
      " [942  22   1]]\n",
      "(943, 3)\n"
     ]
    }
   ],
   "source": [
    "user_features = user_info_df[[\"age\", \"is_male\"]].values\n",
    "print(user_features)\n",
    "print(user_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[662 298  90 ... 574 757 503]\n",
      "(70000,)\n",
      "(70000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_tuple[0])\n",
    "print(train_tuple[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user and item indices from the validation tuple\n",
    "user_tr = train_tuple[0]\n",
    "item_tr = train_tuple[1]\n",
    "\n",
    "# Initialize the combined feature matrix with zeros\n",
    "n_user_item_pairs = len(user_tr)\n",
    "n_user_features = user_features.shape[1]\n",
    "n_movie_features = movie_features.shape[1]\n",
    "n_user_embeddings = pu.shape[0]\n",
    "n_item_embeddings = qi.shape[0]\n",
    "X = np.zeros((n_user_item_pairs, n_user_features + n_movie_features + n_user_embeddings + n_item_embeddings))\n",
    "\n",
    "# Combine user information, movie information, and embeddings\n",
    "for i, (user_id, item_id) in enumerate(zip(user_tr, item_tr)):\n",
    "    user_inner_id = trainset.to_inner_uid(user_id)\n",
    "    item_inner_id = trainset.to_inner_iid(item_id)\n",
    "    if  user_inner_id >= 0 and user_inner_id < algo.pu.shape[0]:\n",
    "        X[i, -n_user_embeddings-n_item_embeddings:-n_item_embeddings] = algo.pu[user_inner_id]\n",
    "        X[i, :n_user_features] = user_features[user_id]\n",
    "    if item_inner_id >=0 and item_inner_id < algo.qi.shape[0]:\n",
    "        X[i, -n_item_embeddings:] = algo.qi[item_inner_id]\n",
    "        X[i, n_user_features:n_user_features+n_movie_features] = movie_features[item_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 2493)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Binary Labeling\n",
    "We'll be using a 4.5 threshold on the ratings for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "# Create target vector based on actual ratings\n",
    "y = np.array(train_tuple[2])\n",
    "\n",
    "y_binary = (y >= 4.5).astype(int)  # Binarize ratings: >= 4 is positive, < 4 is negative\n",
    "print(y_binary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "params = {'C': [0.1, 0.01, 0.001]}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(model, params, scoring='roc_auc', cv=kf, n_jobs=-1)\n",
    "grid_search.fit(X, y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest:\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9), SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Perform grid search with cross-validation\u001b[39;00m\n\u001b[1;32m     28\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params, scoring\u001b[38;5;241m=\u001b[39mauc_scorer, cv\u001b[38;5;241m=\u001b[39mkf, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Get the best model and its corresponding hyperparameters\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grid_search\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m>\u001b[39m best_auc:\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9), SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    # ('Logistic Regression', LogisticRegression(), {'C': [0.1, 1, 10]}),\n",
    "    # ('SVM', SVC(probability=True), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}),\n",
    "    ('Random Forest', RandomForestClassifier(), {'n_estimators': [50, 100, 200], 'max_depth': [None, 5, 10]})\n",
    "]\n",
    "\n",
    "# Create a KFold object for cross-validation\n",
    "\n",
    "# Create a scorer object for AUC\n",
    "auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Perform model selection and hyperparameter tuning\n",
    "best_model = None\n",
    "best_params = None\n",
    "best_auc = 0\n",
    "\n",
    "for name, model, params in models:\n",
    "    print(f\"Evaluating {name}:\")\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search.fit(X, y_binary)\n",
    "    \n",
    "    # Get the best model and its corresponding hyperparameters\n",
    "    if grid_search.best_score_ > best_auc:\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_auc = grid_search.best_score_\n",
    "    \n",
    "    print(f\"Best AUC: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best hyperparameters: {grid_search.best_params_}\\n\")\n",
    "\n",
    "print(\"Best model:\", best_model)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(f\"Best AUC: {best_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating SVM models with n_factors = 2\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vstack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 136\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_factors \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m]:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating SVM models with n_factors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_factors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m     X_combined, y_combined, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_svd_and_prepare_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     tune_and_evaluate_svm(X_combined, y_combined, X_test, y_test)\n",
      "Cell \u001b[0;32mIn[2], line 100\u001b[0m, in \u001b[0;36mtrain_svd_and_prepare_features\u001b[0;34m(n_factors)\u001b[0m\n\u001b[1;32m     97\u001b[0m item_factors \u001b[38;5;241m=\u001b[39m {trainset\u001b[38;5;241m.\u001b[39mto_raw_iid(iid): algo\u001b[38;5;241m.\u001b[39mqi[iid] \u001b[38;5;28;01mfor\u001b[39;00m iid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trainset\u001b[38;5;241m.\u001b[39mn_items)}\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Create features and labels\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_features_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m X_valid, y_valid \u001b[38;5;241m=\u001b[39m prepare_features_and_labels(valid_tuple, user_factors, item_factors, n_factors)\n\u001b[1;32m    102\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m prepare_features_and_labels(test_tuple, user_factors, item_factors, n_factors)\n",
      "Cell \u001b[0;32mIn[2], line 84\u001b[0m, in \u001b[0;36mprepare_features_and_labels\u001b[0;34m(tupl, user_factors, item_factors, n_factors, threshold)\u001b[0m\n\u001b[1;32m     82\u001b[0m ratings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ratings_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: create_features(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserID\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitemID\u001b[39m\u001b[38;5;124m'\u001b[39m], user_factors, item_factors, n_factors), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     83\u001b[0m ratings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (ratings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvstack\u001b[49m(ratings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[1;32m     85\u001b[0m y \u001b[38;5;241m=\u001b[39m ratings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vstack' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "# Load user and movie information\n",
    "user_info = pd.read_csv(\"../data_movie_lens_100k/user_info.csv\")\n",
    "movie_info = pd.read_csv(\"../data_movie_lens_100k/movie_info.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "user_info = user_info.drop(columns=['orig_user_id'])\n",
    "movie_info = movie_info.drop(columns=['orig_item_id'])\n",
    "\n",
    "# Ensure proper column naming\n",
    "user_info.columns = ['user_id', 'age', 'is_male']\n",
    "movie_info.columns = ['item_id', 'title', 'release_year']\n",
    "\n",
    "# Load datasets\n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = load_train_valid_test_datasets()\n",
    "\n",
    "# Convert tuples to a `surprise` dataset\n",
    "def tuple_to_surprise_dataset(tupl):\n",
    "    ratings_dict = {\n",
    "        \"userID\": tupl[0],\n",
    "        \"itemID\": tupl[1],\n",
    "        \"rating\": tupl[2],\n",
    "    }\n",
    "    df = pd.DataFrame(ratings_dict)\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    dataset = Dataset.load_from_df(df[[\"userID\", \"itemID\", \"rating\"]], reader)\n",
    "    return dataset\n",
    "\n",
    "# Movie Title Feature Extraction using TF-IDF\n",
    "titles = movie_info['title'].fillna('')\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "title_vectors = csr_matrix(tfidf.fit_transform(titles))\n",
    "title_dict = {item: title_vectors[i] for i, item in enumerate(movie_info['item_id'])}\n",
    "\n",
    "# Normalize or bucket movie years\n",
    "movie_info['year_normalized'] = (movie_info['release_year'] - movie_info['release_year'].min()) / (movie_info['release_year'].max() - movie_info['release_year'].min())\n",
    "year_dict = {item: movie_info.loc[movie_info['item_id'] == item, 'year_normalized'].values[0] for item in movie_info['item_id']}\n",
    "\n",
    "# Function to create feature vectors\n",
    "def create_features(user_id, item_id, user_factors, item_factors, n_factors):\n",
    "    zero_vector = np.zeros(n_factors)\n",
    "\n",
    "    user_emb = user_factors.get(user_id, zero_vector)\n",
    "    item_emb = item_factors.get(item_id, zero_vector)\n",
    "\n",
    "    # Add demographic features\n",
    "    user_info_row = user_info[user_info['user_id'] == user_id]\n",
    "    if not user_info_row.empty:\n",
    "        is_male = user_info_row.iloc[0]['is_male']\n",
    "        age = user_info_row.iloc[0]['age']\n",
    "    else:\n",
    "        is_male = 0\n",
    "        age = 0\n",
    "\n",
    "    # Add movie title and year features\n",
    "    title_emb = title_dict.get(item_id, csr_matrix((1, 100)))\n",
    "    year_emb = year_dict.get(item_id, 0)\n",
    "\n",
    "    demographic_features = np.array([is_male, age, year_emb])\n",
    "\n",
    "    # Combine all features and return as a sparse matrix\n",
    "    return hstack([csr_matrix(user_emb), csr_matrix(item_emb), csr_matrix(demographic_features), title_emb])\n",
    "\n",
    "# Prepare the final DataFrame for training\n",
    "def prepare_features_and_labels(tupl, user_factors, item_factors, n_factors, threshold=4.5):\n",
    "    ratings_df = pd.DataFrame({\n",
    "        'userID': tupl[0],\n",
    "        'itemID': tupl[1],\n",
    "        'rating': tupl[2]\n",
    "    })\n",
    "    ratings_df['features'] = ratings_df.apply(lambda row: create_features(row['userID'], row['itemID'], user_factors, item_factors, n_factors), axis=1)\n",
    "    ratings_df['label'] = (ratings_df['rating'] >= threshold).astype(int)\n",
    "    X = np.vstack(ratings_df['features']).tocsr()\n",
    "    y = ratings_df['label'].values\n",
    "    return X, y\n",
    "\n",
    "# Function to train and extract features using SVD\n",
    "def train_svd_and_prepare_features(n_factors):\n",
    "    # Train SVD model using the training set\n",
    "    trainset = tuple_to_surprise_dataset(train_tuple).build_full_trainset()\n",
    "    algo = SVD(n_factors=n_factors)\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Extract user and item factors\n",
    "    user_factors = {trainset.to_raw_uid(uid): algo.pu[uid] for uid in range(trainset.n_users)}\n",
    "    item_factors = {trainset.to_raw_iid(iid): algo.qi[iid] for iid in range(trainset.n_items)}\n",
    "\n",
    "    # Create features and labels\n",
    "    X_train, y_train = prepare_features_and_labels(train_tuple, user_factors, item_factors, n_factors)\n",
    "    X_valid, y_valid = prepare_features_and_labels(valid_tuple, user_factors, item_factors, n_factors)\n",
    "    X_test, y_test = prepare_features_and_labels(test_tuple, user_factors, item_factors, n_factors)\n",
    "\n",
    "    # Combine training and validation for model selection\n",
    "    X_combined = np.vstack([X_train, X_valid]).tocsr()\n",
    "    y_combined = np.hstack([y_train, y_valid])\n",
    "\n",
    "    return X_combined, y_combined, X_test, y_test\n",
    "\n",
    "# Function to tune SVM with GridSearchCV\n",
    "def tune_and_evaluate_svm(X_combined, y_combined, X_test, y_test):\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.001]\n",
    "    }\n",
    "\n",
    "    svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring='roc_auc', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), n_jobs=-1)\n",
    "    grid_search.fit(X_combined, y_combined)\n",
    "\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best Cross-Validation AUC Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Test the best model\n",
    "    y_pred_proba = best_svm.predict_proba(X_test)[:, 1]\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "\n",
    "    print(f\"\\nTest Set AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate models for different `n_factors`\n",
    "for n_factors in [2, 10, 50]:\n",
    "    print(f\"\\nEvaluating SVM models with n_factors = {n_factors}\\n\")\n",
    "    X_combined, y_combined, X_test, y_test = train_svd_and_prepare_features(n_factors)\n",
    "    tune_and_evaluate_svm(X_combined, y_combined, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
